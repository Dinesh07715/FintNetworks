export const blogs = [
  {
    id: "1",
    title: "LLM Poisoning - Part 2: Defense Strategies â€“ Building Resilient AI",
    author: "Team Fint",
    date: "Dec 18, 2025",
    image:
      "https://images.unsplash.com/photo-1677442136019-21780ecad995?q=80&w=1400&auto=format&fit=crop",
    heroBg: "from-blue-50 to-slate-100",
    content: [
      {
        type: "heading",
        text: "Defense Strategies: Building Resilient AI Systems",
      },
      {
        type: "paragraph",
        text:
          "The good news? While LLM poisoning is serious, it's not insurmountable. Organizations can implement multi-layered defenses throughout the AI lifecycle.",
      },
      {
        type: "section",
        title: "Layer 1: Data Curation and Validation",
        bullets: [
          "Prioritize trusted, curated data sources over web-scraped content",
          "Implement anomaly detection using statistical methods",
          "Monitor duplicates and poisoning patterns",
          "Filter low-quality content using scoring techniques",
        ],
      },
    ],
  },

  {
    id: "2",
    title: "Engineering AI Guardrails: Designing and Defending Systems",
    author: "Sai Karthik Vemuri",
    date: "Nov 11, 2025",
    image:
      "https://images.unsplash.com/photo-1667372393119-3d4c48d07fc9?q=80&w=1400&auto=format&fit=crop",
    heroBg: "from-purple-50 to-indigo-100",
    content: [
      {
        type: "heading",
        text: "Engineering AI Guardrails",
      },
      {
        type: "paragraph",
        text:
          "AI guardrails ensure systems remain aligned with safety, compliance, and reliability goals across deployments.",
      },
    ],
  },

  {
    id: "3",
    title: "LLM Poisoning - Part 1: The Hidden Threat to AI Systems",
    author: "Team Fint",
    date: "Oct 28, 2025",
    image:
      "https://images.unsplash.com/photo-1551288049-bebda4e38f71?q=80&w=1400&auto=format&fit=crop",
    heroBg: "from-slate-50 to-gray-100",
    content: [
      {
        type: "heading",
        text: "The Hidden Threat to AI Systems",
      },
      {
        type: "paragraph",
        text:
          "LLM poisoning represents a subtle but highly impactful class of attacks that compromise AI behavior.",
      },
    ],
  },
];
